# llm_backend_go
This is a test library to build the llm applications on rust for speed. Frontend will be based using NextJS and Backend written in Go, Typescript and python
Go mostly for the heavy lifting.

## Rust: will the manager.

## Backend:
   * llm_backend
    django-admin startproject llm_backend

## Frontend
   * Drag and Drop Files to build the embeddings.
   * Pop appearing features to give suggestions.
     * NextJS (Drag and Drop to get the file upload and the AI Company:
     * ) --> how to 
     

## Features to be added: 
   * OCR pdf --> send to Go Backend run llm.
   * Check projects for Retrieval Augmented Information.
   * Implementation Retrieval Augmented Generation.
     T4 GPU from Google Colab.

## The Hallucination can also be reduced using this here: 
https://colab.research.google.com/drive/1AXccYmC11kWJ8zZtqS78ZvmBCC7yIPI0#scrollTo=yjs-uPXBrnQs

## Goal of This Backend:
   * Supabase
   * Rust, No Third Party Applications connected to it.
   * Prove hallucination solved

## API Endpoints:
   * pass in .pdfs inside: get the embeddings.

## Pitch on Tech:
   * Rust Backend, end to end solutions. 
     User friendly API
     user privacy
     No hallucination from the AI Agent.

## Pitch on Product:
   * Netflix Subscription churn prediction, automate sending personalised mails. a/B testing
   * Find, contact, and close your ideal buyers with over 265M contacts and streamlined engagement workflows powered by AI. 

    * Give a voice to the data of company.
    * Sales Intelligence: figuring out why sales is so poor.
    * Talk to Sales Data, Churn prediction. 
    * Small Startups --> Get their leads.

    * Big Companies --> Really good customer service.
    * Companies do not have the expertise to find new sales lead. 

## Builders Build. We help you sell from day 1 so you can focus on building.
   -- Sales Intelligence.
       -- send leads. Inbound and outbound.
       -- 
   -- Legal matters: we help you avoid large corporate fines, keep company in standing order, finance analysis.
   -- Draft Letters: 
   -- Test the speed of inference: https://www.youtube.com/watch?v=h6qZM76eOYE
   -- 

## Manager: 
   * Langchain-rs: rust based langchain 
   * Embeddings: Loaders for the documents.
   * LLaMa or OpenAI  
   * Sequence of OpenAI loaders:
   * Get the Data with the Embeddings: 
   * Close Solution: No third party apis from other providers.
   * https://github.com/gaxler/llama2.rs, the rust version of this company.

## Technical Performance analysis of inference
   140mb: model fast inference.

## Analysis of the code:
    https://colab.research.google.com/drive/1t3NRHDjs25jS5tgpmSdlw1gGw9HVQRVZ#scrollTo=GpGBT-_SYOJl

## Ways of Working:
   OpenAI Code Interpreter: https://github.com/kesor/chatgpt-code-plugin --> code chatgpt-code plugin (install it!)

## Sell the Software Even from beforehand (super important) (Door to Door to Companies online)

##  